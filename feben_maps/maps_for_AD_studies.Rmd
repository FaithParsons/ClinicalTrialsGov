---
title: "Map visualization for AD studies"
author: "Feben Asefaha"
date: "12/1/2017"
output: html_document
---

```{r setup, include=FALSE}
#loading packages
library(tidyverse)
library(dplyr)
library(janitor)
library(haven)
library(stringr)
library(knitr)
library(plotly)
library(ggplot2)
library(viridis)
library(flexdashboard)
library(readr)
library(readxl)
library(ggmap)
library(leaflet)
library(splitstackshape)
library(purrr)
library(mapview)
library(webshot)

knitr::opts_chunk$set(echo = TRUE)
```


The variables I am interested in utilizing are 

PHASE
ID 
AGE
GENDER
RECRUITMENT STAGE
INTERVENTIONS
LOCATION

From LOCATION, cleaning to derive CITY, STATE

Using ggmap function geocode(), get the lat and long for each city using the Google Maps Geocoding API.


(this is accessing the web, so you can't send too many at once! Otherwise you will get back as NAs. So I will make filtering by state a requirement)

Plot those coordinates using leaflet package

(See below)


Leaflet is supposed to work well with Shiny...

So intend to add drop down menus:

STATE(necessary; if you get an NA, reload and it should be fine)
RECRUITMENT(Recruiting, Completed, By invitation only, etc)
PHASE (1, 2, 1 and 2)
INTERVENTION (Behavioral, Genetic, Device, Drug, Other)
AGE (categorized into groups)
GENDER (Female, Male, All)


Here is my ordered plan:

1) Download data (SearchTableResults.csv)
2) In the location variable, every time you see a usable address, it's in a "City, State, Country" format. So I have to locate strings that end in "United States" (We are only focusing on United States studies)
3) Once "city, state, country" are isolated, separate into three columns 
4) Mutate a new column that gives state abbreviation (eg. AK, CA, NY)
5) Merge "city" and "state_code" so geocode() (from ggmap) may be applied. This will give me latitude and longitude.
6) Give latitude and longitude their own columns
7) Can map coordinate pairs using Leaflet package

After this, Shiny can be applied for widget interactivity.


In the initial data import and cleanup, I select the variables that I am interested in. Using string functions, I filter only for locations that have "United States" in them. Since some studies include more than one phase, I break each phase into its own column. 
```{r Part 1 loading data}

## import data, select variables of interest, filter for US locations 
AD_search_results <- 
  #read_csv("../data/SearchResultsTable.csv") %>% 
  read_csv("../Data/SearchResultsTable.csv") %>%  
  clean_names() %>% 
  select(nct_number, recruitment, interventions, gender, age,
         phases, enrollment, study_type, locations) %>% 
  filter(str_detect(locations, "United States")) %>%
  separate(phases, into = c("phase_a", "phase_b", "phase_c", "phase_d"), sep = "\\|")  
  # separate(locations, into = c(), sep = "\\|") %>% 
  

## Data set from this step: AD_search_results
```


Since many studies encompass several different locations, which were separated by the vertical pipe character ( | ), I split them up into multiple columns, and used a funtion to search for character strings in the "City, State, Country" format that ended in "United States". The result was a data set that had locations spread over hundreds of columns.
```{r  Part 2 FUNCTION TO GET EXTRACT LOCATIONS}

## separate multiple locations into individual columns
AD_search_results_split_locations <- AD_search_results %>%
  cSplit("locations", sep = '|')

## finding addresses in United States
clean_loc = function(location) {
  
  result <- location
  
  if (grepl("United States", location, fixed = TRUE)) {
    result = sub(".*, (.+), (.+), United States(.*)", "\\1, \\2", location)
  } else {
    result  = ""
  }
  
  result
}



for (i in 12:dim(AD_search_results_split_locations)[2]) {
  AD_search_results_split_locations[[i]] = map(AD_search_results_split_locations[[i]], clean_loc)
}

## Data set from this step: AD_search_results_split_locations
```



For further tidying, I gather the locations and phases into one column. I also reduce the intervention column to only its class (Behavioral, Drug, Device...) for easier widget use. After removing any stray country names, I remove any duplicate entries. This is easily achievable because each study has a unique ID number, the "nct_number".
```{r Part 3 CLEANUP}

## gathering locations and phases
AD_edit <- AD_search_results_split_locations %>% 
  gather( key = place, value = location, locations_001:locations_348) %>% 
  select(-place) %>% 
  gather( key = remove, value = phase, phase_a:phase_d) %>% 
  select(-remove)

## simplifying interventions, removing additional country indicator 
## city and state columns
AD_edit_unique <- AD_edit %>% 
  separate(interventions, into = c("interventions", "remove"), sep = ':') %>% 
  select(-remove) %>%
  mutate(location = sub("(.+), United States", "\\1", location)) %>% 
  separate(location, into = c("city", "state"), sep = ", ") %>% 
  unique() 
  
## Data set from this set is AD_edit_unique

```

The ages can be very specific and disparate (e.g. 60-80, 18 and older, up to 100), and would be too much on their own for a drop-down menu. Since age groups labels (like "Adult, Senior", "Child, Adult, Senior") are also listed with numerical ages in this column, it's more useful to use those. They are usually in parentheses, so we can extract them using the code below.
```{r Part 4 AGE GROUPS variable}


## cleaning up AGE variable for drop-down menu

##   BREAKDOWN OF AGE GROUPS FOR INLINE CODE
# AD_edit_unique %>% 
#   group_by(age) %>% 
#   summarize()

## Child is 0 - 17, Adult is 18 - 65, Senior is 66 +
## extracting age group labels

AD_new <- AD_edit_unique %>% 
  mutate(age = sub("^([^()]+)$", "(\\1)", age)) %>% 
  mutate(cleaned_age = str_extract(age, "\\(.+\\)")) %>%
  mutate(cleaned_age = sub("\\((.+)\\)", "\\1", cleaned_age)) %>% 
   select(-age, -enrollment) 

#AD_new %>% 
  #count(cleaned_age) 

## Data set from this step is AD_new

```

In order to use geocode for city locations, I need to also have state abbreviations after it ("Atlanta, GA"), so I mutate a new column with abbreviations, taking special care with Washington D.C. After this, I filter out any address that doesn't have a state associated with it, because it won't work with the final map. I also replace blank entries in the dataset with "Not available" because that can be a viable option for other menus. 
```{r Part 5 SETTING UP A COLUMN FOR GEOCODE ACCESS}

## getting state abbrevs


##  CHECKING THE STATE COLUMN
# AD_new %>% 
#   count(state)

state_list <- list()
state_list[['name']] = c(state.name,"District of Columbia")
state_list[['abb']] = c(state.abb,"DC")

state_lookup <- setNames(state_list$abb, state_list$name)

##filter out any entry without state because can't map it  
AD_newer <- AD_new %>% 
  rename(state_name = state) %>%
  filter(!is.na(state_name)) %>%
  mutate(state_code = state_lookup[state_name])

## merging city and state code
AD_newer$geo_place <- paste(AD_newer$city, ",", AD_newer$state_code)

## finding all empty cells and replace each one with a string
AD_newer[is.na(AD_newer)] <- "Not available"

## Dataset from this set is AD_newer 
```


In an R object, latitude and longitude were obtained for the cities.

It became clear that live coordinate calls to the Google Maps API would not be feasible
```{r Part 6}

## Faith, should we include your rds code here? 


```




Merging the lat and long .rds to study dataset! 
```{r Part 7, merging the the lat and long rds with study data}

## rename the "geo_place" column to "location""
AD_newest <- AD_newer %>% 
  rename(location = geo_place) 
  
## get the rds that Faith developed that has all locations and their associated lat and long coordinates
study_coordinates <- readRDS("../Data/geocoded_studies.rds") %>% 
  select(location, lat, lng) %>% 
  mutate(location = gsub(", ([A-Z])", " , \\1", location))

## join them by location
AD_final <- inner_join(AD_newest, study_coordinates) %>% 
  unique()

#View(AD_final)

write.csv(AD_final, file = "final_data_for_leaflet.csv")

## Use this dataset to make maps!


```




Here is an interactive leaflet map that demonstrates locations of studies, filtered by specifications that are to be selected by the user

```{r first maps}


#retrieve code from new file
AD_final <- read_csv("./final_data_for_leaflet.csv") %>% 
  select(-X1) %>% 
  rename(latitude = lat,
         longitude = lng)

AD_final %>% 
  filter(study_type == "Interventional",
         phase == "Phase 3",
         recruitment == "Recruiting") %>% 
  leaflet() %>%
  addTiles() %>%
  addMarkers(clusterOptions = markerClusterOptions())



knitr::opts_chunk$set(echo = TRUE)
```
















