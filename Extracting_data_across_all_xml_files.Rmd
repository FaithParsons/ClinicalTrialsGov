---
title: "Extracting_data_across_all_xml_files"
author: "Imaani Easthausen"
date: "November 9, 2017"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(rvest)
library(XML)
library(plyr)
library(tidyverse)
```


Below is a method for extracting from each of the study-related pages. Data were downloaded on 09/11/2017 and stored in the `Data > xml_files` folder located on the github page. `xml_files` is a folder containing one .xml file for each study. The .xml file contains all data that was available on the study webpage at time of download. Below we extract all variables contained in each .xml file and store them to a .csv file titled `alzheimers_data` and also located in the `Data` folder.



```{r}
  get_node = function(node_name, xml_file) {
    xmlTreeParse(xml_file, useInternal = TRUE) %>%
    xmlRoot() %>%
    xpathSApply(node_name, xmlValue)
  }

  get_node_value = function(node_name, xml_file) {
    xpathSApply(xml_file, node_name, xmlValue)
  }

files = list.files("data/xml_files")

list_of_dfs = list()

for(i in files) {

  
  file_path = paste("data/xml_files/", i, sep = '')
  

  xml_file = read_xml(file_path) %>%
    xmlTreeParse(useInternal = TRUE) %>%
    xmlRoot() 

  node_names = xml_file %>%
    names() %>%
    unique() #is this step removing data??

   l =  sapply(node_names, get_node_value, xml_file)


  
  df = lapply(l, paste, collapse=", ") %>%
    as.tibble()
  
  list_of_dfs[[i]] = df

}

alzheimers = ldply(list_of_dfs)

write.csv(alzheimers, file = "alzheimers_data.csv")

```


